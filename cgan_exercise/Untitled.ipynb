{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, concatenate, Flatten, Conv2DTranspose, Reshape, Dense\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "def normalize(img):  # -1 ~ 1\n",
    "    return (img - 127.5) / 127.5\n",
    "\n",
    "def denormalize(img):\n",
    "    return (img * 127.5 + 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do data process in dataset map function\n",
    "x_train = normalize(x_train[..., tf.newaxis])\n",
    "x_test = normalize(x_test[..., tf.newaxis])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "x_train = (x_train, y_train)\n",
    "x_test = (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = (np.random.sample((100, 2)), np.random.sample((100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: optimize this dataset (map function)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(10000).padded_batch(batch_size, remain)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test).shuffle(10000).padded_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_1 = Conv2D(64, kernel_size=(4, 4), strides=2, padding='same', activation='relu')\n",
    "        self.conv_2 = Conv2D(128, kernel_size=(4, 4), strides=2, padding='same', activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, img, condition):\n",
    "        img = self.conv_1(img)\n",
    "        img = self.conv_2(img)\n",
    "        feature_vector = self.flatten(img)\n",
    "        concated_layer = concatenate([feature_vector, condition])\n",
    "        logit = self.dense_1(concated_layer)\n",
    "        return logit\n",
    "    \n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_1 = Dense(7 * 7 * 128, activation='relu')\n",
    "        self.reshape = Reshape((7, 7, 128))\n",
    "        self.deconv_1 = Conv2DTranspose(128, kernel_size=(4, 4), strides=2, padding='same', activation='relu')\n",
    "        self.deconv_2 = Conv2DTranspose(64, kernel_size=(4, 4), strides=2, padding='same', activation='relu')\n",
    "        self.deconv_3 = Conv2DTranspose(1, kernel_size=(1, 1), strides=1, padding='valid', activation='tanh')\n",
    "        \n",
    "    def call(self, latent, condition):\n",
    "        conditioned_latent = concatenate([latent, condition])\n",
    "        x = self.dense_1(conditioned_latent)\n",
    "        x = self.reshape(x)\n",
    "        x = self.deconv_1(x)\n",
    "        x = self.deconv_2(x)\n",
    "        x = self.deconv_3(x)\n",
    "        return x\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entrophy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = tf.random.normal([32, 100])\n",
    "condition = y_train[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape\n",
    "condition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb52920a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_img = generator(latent, condition)\n",
    "fake_img[0].shape\n",
    "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(fake_output, real_output):\n",
    "    real = cross_entrophy(tf.ones_like(real_output), real_output)\n",
    "    fake = cross_entrophy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real + fake\n",
    "\n",
    "def get_gen_loss(fake_output):\n",
    "    return cross_entrophy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss : 0.46979817748069763 d_loss : 1.3146380186080933\n",
      "g_loss : 0.47053956985473633 d_loss : 1.3128207921981812\n",
      "g_loss : 0.4711715579032898 d_loss : 1.3102281093597412\n",
      "g_loss : 0.4715721011161804 d_loss : 1.3079032897949219\n",
      "g_loss : 0.4727080166339874 d_loss : 1.3044523000717163\n",
      "g_loss : 0.47283148765563965 d_loss : 1.3039311170578003\n",
      "g_loss : 0.4734465777873993 d_loss : 1.3015103340148926\n",
      "g_loss : 0.47297531366348267 d_loss : 1.3034213781356812\n",
      "g_loss : 0.47388654947280884 d_loss : 1.2999005317687988\n",
      "g_loss : 0.4735923409461975 d_loss : 1.3009793758392334\n",
      "g_loss : 0.47344884276390076 d_loss : 1.3010070323944092\n",
      "g_loss : 0.47318437695503235 d_loss : 1.3013968467712402\n",
      "g_loss : 0.4732598662376404 d_loss : 1.3007535934448242\n",
      "g_loss : 0.473976194858551 d_loss : 1.300360918045044\n",
      "g_loss : 0.47339510917663574 d_loss : 1.3003640174865723\n",
      "g_loss : 0.4738727807998657 d_loss : 1.3006277084350586\n",
      "g_loss : 0.4745772182941437 d_loss : 1.2988840341567993\n",
      "g_loss : 0.4744669795036316 d_loss : 1.2997376918792725\n",
      "g_loss : 0.47474056482315063 d_loss : 1.2993651628494263\n",
      "g_loss : 0.47337329387664795 d_loss : 1.3030285835266113\n",
      "g_loss : 0.4726408123970032 d_loss : 1.3057578802108765\n",
      "g_loss : 0.47109925746917725 d_loss : 1.3094325065612793\n",
      "g_loss : 0.47069087624549866 d_loss : 1.3118430376052856\n",
      "g_loss : 0.4717324674129486 d_loss : 1.3121790885925293\n",
      "g_loss : 0.4727625250816345 d_loss : 1.314514398574829\n",
      "g_loss : 0.4753803014755249 d_loss : 1.314026117324829\n",
      "g_loss : 0.4787735939025879 d_loss : 1.3115909099578857\n",
      "g_loss : 0.4822259843349457 d_loss : 1.31231689453125\n",
      "g_loss : 0.48728471994400024 d_loss : 1.3098182678222656\n",
      "g_loss : 0.49245816469192505 d_loss : 1.3095054626464844\n",
      "g_loss : 0.49770402908325195 d_loss : 1.309831142425537\n",
      "g_loss : 0.5045566558837891 d_loss : 1.3076025247573853\n",
      "g_loss : 0.5100772976875305 d_loss : 1.3103840351104736\n",
      "g_loss : 0.5163541436195374 d_loss : 1.3108845949172974\n",
      "g_loss : 0.5216250419616699 d_loss : 1.3154821395874023\n",
      "g_loss : 0.5255076885223389 d_loss : 1.3185739517211914\n",
      "g_loss : 0.5294604897499084 d_loss : 1.3191864490509033\n",
      "g_loss : 0.5330193042755127 d_loss : 1.32597017288208\n",
      "g_loss : 0.5341289043426514 d_loss : 1.3267426490783691\n",
      "g_loss : 0.534888744354248 d_loss : 1.3298200368881226\n",
      "g_loss : 0.5328720808029175 d_loss : 1.3321418762207031\n",
      "g_loss : 0.5314822196960449 d_loss : 1.3391282558441162\n",
      "g_loss : 0.5285065770149231 d_loss : 1.3458999395370483\n",
      "g_loss : 0.5274460315704346 d_loss : 1.3411543369293213\n",
      "g_loss : 0.5241939425468445 d_loss : 1.344315767288208\n",
      "g_loss : 0.5226409435272217 d_loss : 1.3534804582595825\n",
      "g_loss : 0.5217583775520325 d_loss : 1.3444825410842896\n",
      "g_loss : 0.5201026201248169 d_loss : 1.3490040302276611\n",
      "g_loss : 0.5201512575149536 d_loss : 1.355710506439209\n",
      "g_loss : 0.5207337737083435 d_loss : 1.3518109321594238\n",
      "g_loss : 0.5196653604507446 d_loss : 1.3433855772018433\n",
      "g_loss : 0.5221258401870728 d_loss : 1.3427455425262451\n",
      "g_loss : 0.5228021740913391 d_loss : 1.3379658460617065\n",
      "g_loss : 0.5227248072624207 d_loss : 1.3345950841903687\n",
      "g_loss : 0.5236191749572754 d_loss : 1.3263686895370483\n",
      "g_loss : 0.5266683101654053 d_loss : 1.3312000036239624\n",
      "g_loss : 0.5292466282844543 d_loss : 1.3148221969604492\n",
      "g_loss : 0.5293558835983276 d_loss : 1.3156991004943848\n",
      "g_loss : 0.5316653847694397 d_loss : 1.2997050285339355\n",
      "g_loss : 0.5325538516044617 d_loss : 1.2907540798187256\n",
      "g_loss : 0.5338284969329834 d_loss : 1.2769360542297363\n",
      "g_loss : 0.5336836576461792 d_loss : 1.286447286605835\n",
      "g_loss : 0.5305331349372864 d_loss : 1.2866841554641724\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-505003302d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_disc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gen_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mg_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f90a9e69e5de>\u001b[0m in \u001b[0;36mget_gen_loss\u001b[0;34m(fake_output)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_gen_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entrophy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[0;32m--> 128\u001b[0;31m           losses, sample_weight, reduction=self._get_reduction())\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/losses_utils.py\u001b[0m in \u001b[0;36mcompute_weighted_loss\u001b[0;34m(losses, sample_weight, reduction, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0minput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     weighted_losses = tf_losses_utils.scale_losses_by_sample_weight(\n\u001b[0;32m--> 107\u001b[0;31m         losses, sample_weight)\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Apply reduction function to the individual weighted losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_weighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/losses/util.py\u001b[0m in \u001b[0;36mscale_losses_by_sample_weight\u001b[0;34m(losses, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;31m# Broadcast weights if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m   \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_broadcast_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/weights_broadcast_ops.py\u001b[0m in \u001b[0;36mbroadcast_weights\u001b[0;34m(weights, values)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massert_broadcastable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       return math_ops.multiply(\n\u001b[0;32m--> 169\u001b[0;31m           weights, array_ops.ones_like(values), name=scope)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mones_like\u001b[0;34m(tensor, dtype, name, optimize)\u001b[0m\n\u001b[1;32m   2492\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mall\u001b[0m \u001b[0melements\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m   \"\"\"\n\u001b[0;32m-> 2494\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mones_like_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data in train_dataset:\n",
    "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "            real_img, label = data\n",
    "            latent = tf.random.normal([32, 100])\n",
    "            fake_img = generator(latent, label)\n",
    "\n",
    "            real_output = discriminator(real_img, label)\n",
    "            fake_output = discriminator(fake_img, label)\n",
    "            d_loss = get_disc_loss(fake_output, real_output)\n",
    "            g_loss = get_gen_loss(fake_output)\n",
    "\n",
    "            g_gradients = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "            d_gradients = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "            generator_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n",
    "            discriminator_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n",
    "\n",
    "            print(f\"g_loss : {g_loss} d_loss : {d_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Reshape, Conv2DTranspose, Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow 2 버전을 사용하여 간단한 MNIST gan model 을 작성해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img - 127.5) / 127.5\n",
    "\n",
    "def denormalize(norm_img):\n",
    "    return norm_img * 127.5 + 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = normalize(x_train), normalize(y_train)\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(10000).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_1 = Conv2D(512, (3, 3), activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(256)\n",
    "        self.logits = Dense(1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "    \n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_1 = Dense(7 * 7 * 1024)\n",
    "        self.reshape = Reshape((7, 7, 1024))\n",
    "        self.conv_1 = Conv2DTranspose(512, (3, 3), strides=(1, 1), padding='same')\n",
    "        self.conv_2 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')\n",
    "        self.conv_3 = Conv2DTranspose(1, (3, 3), strides=(2,2), padding='same', activation='tanh')\n",
    "        \n",
    "    def call(self, latent):\n",
    "        x = self.dense_1(latent)\n",
    "        x = self.reshape(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        assert x.shape == (BATCH_SIZE, 14, 14, 256)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = self.conv_3(x)\n",
    "        assert x.shape == (BATCH_SIZE, 28, 28, 1)\n",
    "        return x\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb2d1c0c18>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent = tf.random.normal([BATCH_SIZE, 100])\n",
    "generated_img = generator(latent)\n",
    "plt.imshow(generated_img[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8.1035710e-04]\n",
      " [ 3.1881640e-04]\n",
      " [ 1.6445359e-03]\n",
      " [ 2.1021604e-04]\n",
      " [-6.0969149e-05]\n",
      " [ 7.4563723e-04]\n",
      " [ 4.6906283e-04]\n",
      " [ 1.4775991e-03]\n",
      " [ 1.2410610e-03]\n",
      " [ 1.4471679e-03]\n",
      " [ 2.3385268e-03]\n",
      " [ 7.9606759e-04]\n",
      " [ 7.9161604e-04]\n",
      " [ 6.2045990e-05]\n",
      " [ 1.0952681e-03]\n",
      " [ 7.1119552e-04]\n",
      " [-1.4559081e-04]\n",
      " [ 7.8976667e-04]\n",
      " [ 3.5076076e-04]\n",
      " [ 9.8982616e-04]\n",
      " [ 4.4881273e-04]\n",
      " [ 4.8382342e-04]\n",
      " [ 1.5134676e-03]\n",
      " [ 1.8941304e-03]\n",
      " [ 1.4227851e-03]\n",
      " [ 1.7405942e-04]\n",
      " [ 2.6376343e-03]\n",
      " [ 1.2400879e-03]\n",
      " [ 5.3448405e-04]\n",
      " [ 4.8515241e-04]\n",
      " [ 9.8458910e-04]\n",
      " [ 1.2651959e-03]], shape=(32, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_img)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gen_acc = tf.keras.metrics.BinaryAccuracy(name=\"gen_acc\")\n",
    "get_disc_acc = tf.keras.metrics.BinaryAccuracy(name=\"disc_acc\")\n",
    "\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_imgs = generator(noise)\n",
    "        fake_outputs = discriminator(generated_imgs)\n",
    "        real_outputs = discriminator(images)\n",
    "        gen_loss = generator_loss(generated_imgs)\n",
    "        disc_loss = discriminator_loss(real_outputs, fake_outputs)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    gen_acc = get_gen_acc(tf.ones_like(fake_outputs), fake_outputs)\n",
    "    disc_acc = (get_disc_acc(tf.zeros_like(fake_outputs), fake_outputs) + get_disc_acc(tf.ones_like(real_outputs), real_outputs)) / 2\n",
    "    print(f\"g_loss == {gen_loss:4.2f} / g_accuracy == {gen_acc:4.2f} / d_loss == {disc_loss:4.2f} / d_accuracy == {disc_acc:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 17:39:09.977029 4545033664 base_layer.py:1814] Layer discriminator_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 1.36 / d_accuracy == 0.75\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.74 / d_accuracy == 0.71\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.75 / d_accuracy == 0.82\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.74 / d_accuracy == 0.87\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.71 / d_accuracy == 0.89\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.67 / d_accuracy == 0.91\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.61 / d_accuracy == 0.93\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.50 / d_accuracy == 0.94\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.36 / d_accuracy == 0.94\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.22 / d_accuracy == 0.95\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.12 / d_accuracy == 0.95\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.05 / d_accuracy == 0.96\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.02 / d_accuracy == 0.96\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.96\n",
      "g_loss == 0.64 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.97\n",
      "g_loss == 0.64 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.97\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.97\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.97\n",
      "g_loss == 0.62 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.97\n",
      "g_loss == 0.62 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.97\n",
      "g_loss == 0.61 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.61 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.58 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.59 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.58 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.57 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.57 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.55 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.98\n",
      "g_loss == 0.55 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.53 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.54 / g_accuracy == 0.00 / d_loss == 0.07 / d_accuracy == 0.98\n",
      "g_loss == 0.53 / g_accuracy == 0.00 / d_loss == 0.19 / d_accuracy == 0.98\n",
      "g_loss == 0.52 / g_accuracy == 0.00 / d_loss == 0.04 / d_accuracy == 0.98\n",
      "g_loss == 0.50 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.50 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.47 / g_accuracy == 0.00 / d_loss == 0.05 / d_accuracy == 0.98\n",
      "g_loss == 0.50 / g_accuracy == 0.00 / d_loss == 0.48 / d_accuracy == 0.98\n",
      "g_loss == 0.50 / g_accuracy == 0.01 / d_loss == 0.81 / d_accuracy == 0.98\n",
      "g_loss == 0.46 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.46 / g_accuracy == 0.01 / d_loss == 0.03 / d_accuracy == 0.98\n",
      "g_loss == 0.46 / g_accuracy == 0.01 / d_loss == 0.30 / d_accuracy == 0.98\n",
      "g_loss == 0.42 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.98\n",
      "g_loss == 0.42 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.43 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.38 / g_accuracy == 0.01 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.39 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.38 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.38 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.36 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.37 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.36 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.37 / g_accuracy == 0.01 / d_loss == 0.17 / d_accuracy == 0.99\n",
      "g_loss == 0.35 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.35 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.35 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.34 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.34 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.34 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.34 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.33 / g_accuracy == 0.01 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for train_imgs in train_dataset:\n",
    "        train_step(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Reshape, Conv2DTranspose, Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow 2 버전을 사용하여 간단한 MNIST gan model 을 작성해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img - 127.5) / 127.5\n",
    "\n",
    "def denormalize(norm_img):\n",
    "    return norm_img * 127.5 + 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = normalize(x_train), normalize(y_train)\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(10000).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_1 = Conv2D(32, (3, 3), activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(64)\n",
    "        self.logits = Dense(1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "    \n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_1 = Dense(7 * 7 * 256)\n",
    "        self.reshape = Reshape((7, 7, 256))\n",
    "        self.conv_1 = Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same')\n",
    "        self.conv_2 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')\n",
    "        self.conv_3 = Conv2DTranspose(1, (3, 3), strides=(2,2), padding='same', activation='tanh')\n",
    "        \n",
    "    def call(self, latent):\n",
    "        x = self.dense_1(latent)\n",
    "        x = self.reshape(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        assert x.shape == (BATCH_SIZE, 14, 14, 64)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = self.conv_3(x)\n",
    "        assert x.shape == (BATCH_SIZE, 28, 28, 1)\n",
    "        return x\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb2d068390>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent = tf.random.normal([BATCH_SIZE, 100])\n",
    "generated_img = generator(latent)\n",
    "plt.imshow(generated_img[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8.79095867e-03]\n",
      " [ 1.34523283e-03]\n",
      " [-9.00788419e-03]\n",
      " [ 7.03015737e-03]\n",
      " [-6.66797068e-03]\n",
      " [ 9.13908938e-04]\n",
      " [-7.47238379e-03]\n",
      " [ 1.47853699e-02]\n",
      " [-2.87819095e-03]\n",
      " [-8.55504069e-04]\n",
      " [ 4.26709186e-03]\n",
      " [-8.28159135e-03]\n",
      " [-2.34679156e-03]\n",
      " [ 1.95480045e-03]\n",
      " [ 7.70206843e-03]\n",
      " [ 7.51884747e-03]\n",
      " [ 6.11102721e-03]\n",
      " [ 8.56222934e-04]\n",
      " [ 4.64065280e-03]\n",
      " [-1.55676436e-03]\n",
      " [-6.77490979e-03]\n",
      " [-3.03438399e-04]\n",
      " [ 9.01017571e-04]\n",
      " [ 4.60260641e-03]\n",
      " [ 3.23883258e-04]\n",
      " [ 5.73371071e-03]\n",
      " [-2.83282204e-03]\n",
      " [ 1.36918705e-02]\n",
      " [ 6.74744416e-03]\n",
      " [ 6.01198990e-05]\n",
      " [ 1.07670994e-02]\n",
      " [-5.17419213e-03]], shape=(32, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_img)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gen_acc = tf.keras.metrics.BinaryAccuracy(name=\"gen_acc\")\n",
    "get_disc_acc = tf.keras.metrics.BinaryAccuracy(name=\"disc_acc\")\n",
    "\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_imgs = generator(noise)\n",
    "        fake_outputs = discriminator(generated_imgs)\n",
    "        real_outputs = discriminator(images)\n",
    "        gen_loss = generator_loss(generated_imgs)\n",
    "        disc_loss = discriminator_loss(real_outputs, fake_outputs)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    gen_acc = get_gen_acc(tf.ones_like(fake_outputs), fake_outputs)\n",
    "    disc_acc = (get_disc_acc(tf.zeros_like(fake_outputs), fake_outputs) + get_disc_acc(tf.ones_like(real_outputs), real_outputs)) / 2\n",
    "    print(f\"g_loss == {gen_loss:4.2f} / g_accuracy == {gen_acc:4.2f} / d_loss == {disc_loss:4.2f} / d_accuracy == {disc_acc:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 17:32:07.772555 4545033664 base_layer.py:1814] Layer discriminator_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 1.30 / d_accuracy == 0.75\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.85 / d_accuracy == 0.71\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.76 / d_accuracy == 0.82\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.74 / d_accuracy == 0.87\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.73 / d_accuracy == 0.89\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.72 / d_accuracy == 0.91\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.71 / d_accuracy == 0.93\n",
      "g_loss == 0.69 / g_accuracy == 0.00 / d_loss == 0.70 / d_accuracy == 0.94\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.69 / d_accuracy == 0.94\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.67 / d_accuracy == 0.95\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.65 / d_accuracy == 0.95\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.63 / d_accuracy == 0.96\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.60 / d_accuracy == 0.96\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.58 / d_accuracy == 0.96\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.55 / d_accuracy == 0.97\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.52 / d_accuracy == 0.97\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.48 / d_accuracy == 0.97\n",
      "g_loss == 0.68 / g_accuracy == 0.00 / d_loss == 0.45 / d_accuracy == 0.97\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.41 / d_accuracy == 0.97\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.37 / d_accuracy == 0.97\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.34 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.30 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.27 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.23 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.19 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.17 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.14 / d_accuracy == 0.98\n",
      "g_loss == 0.67 / g_accuracy == 0.00 / d_loss == 0.12 / d_accuracy == 0.98\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.09 / d_accuracy == 0.98\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.08 / d_accuracy == 0.98\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.06 / d_accuracy == 0.98\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.05 / d_accuracy == 0.98\n",
      "g_loss == 0.66 / g_accuracy == 0.00 / d_loss == 0.03 / d_accuracy == 0.98\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.03 / d_accuracy == 0.99\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.02 / d_accuracy == 0.99\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.02 / d_accuracy == 0.99\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.02 / d_accuracy == 0.99\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.65 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.64 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.64 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.64 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.63 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.62 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.62 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.62 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.61 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.61 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.61 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.60 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.60 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.59 / g_accuracy == 0.00 / d_loss == 0.02 / d_accuracy == 0.99\n",
      "g_loss == 0.59 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.59 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.58 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.57 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.58 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.57 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.56 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.56 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.56 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.55 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.54 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.54 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.54 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.54 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.53 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.53 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.52 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.51 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.53 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.52 / g_accuracy == 0.00 / d_loss == 0.03 / d_accuracy == 0.99\n",
      "g_loss == 0.51 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.51 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.48 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.47 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.49 / g_accuracy == 0.00 / d_loss == 0.01 / d_accuracy == 0.99\n",
      "g_loss == 0.48 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.48 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.47 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.49 / g_accuracy == 0.00 / d_loss == 0.03 / d_accuracy == 0.99\n",
      "g_loss == 0.45 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.47 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.46 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.45 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.45 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.46 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.45 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.44 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.42 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.42 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.42 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.39 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 0.99\n",
      "g_loss == 0.40 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.39 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.39 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.37 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.39 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.38 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.38 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.38 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.37 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.37 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.37 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.37 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.36 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.36 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.36 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.36 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.35 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.34 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.33 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.32 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n",
      "g_loss == 0.31 / g_accuracy == 0.00 / d_loss == 0.00 / d_accuracy == 1.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f9bcf7f9b12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_imgs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-0d4021a3aed8>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    483\u001b[0m           update_ops.extend(\n\u001b[1;32m    484\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 485\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2146\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2148\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    465\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    202\u001b[0m           \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;34m\"ResourceApplyAdam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mbeta1_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m         \"use_locking\", use_locking, \"use_nesterov\", use_nesterov)\n\u001b[0m\u001b[1;32m   1526\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for train_imgs in train_dataset:\n",
    "        train_step(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

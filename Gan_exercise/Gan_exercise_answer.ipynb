{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Reshape, Conv2DTranspose, Activation, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow 2 버전을 사용하여 간단한 MNIST gan model 을 작성해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  tensorflow keras에서 제공하는 mnist 데이터셋을 가지고 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주어진 이미지는 0 ~ 255 사이의 값으로 이루어져 있습니다.\n",
    "### 학습하기 위해 이미지 픽셀 값들을 -1 ~ 1 사이의 값으로 매핑 시켜야 합니다.\n",
    "### 이 과정을 normalize 라고 합니다. \n",
    "### normalize 와 denormalize 함수를 정의하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    \"\"\" normalize img\n",
    "    Args: \n",
    "        img: 28 * 28 size numpy array of mnist img. range(0 ~ 255)\n",
    "    Returns:\n",
    "        img: 28 * 28 size numpy array of normalized mnist img. range (-1 ~ 1)\n",
    "    \"\"\"\n",
    "    return (img - 127.5) / 127.5\n",
    "\n",
    "def denormalize(norm_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        norm_img : 28 * 28 size numpy array of normalized mnist img. range (-1 ~ 1)\n",
    "    Returns:\n",
    "        denormalized img: 28 * 28 size numpy array of denormalized mnist img. range (0 ~ 255)\"\"\"\n",
    "    return norm_img * 127.5 + 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize 시킨 mnist 이미지들과, tensorflow dataset API를 사용하여, \n",
    "### batch size만큼 데이터를 제공하는 train, test dataset 을 정의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = normalize(x_train), normalize(y_train)\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(10000).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator가 생성한 이미지와, 원래 이미지를 구분하는 discriminator를 만들어 봅시다.\n",
    "### init 함수에는 discriminator가 사용할 layer들을 정의하고, call 함수에서 정의된 layer들에 input 데이터를 통과시키세요.\n",
    "\n",
    "#### 3 * 3 커널을 512 개 가지고 있는 conv layer -> relu -> Flatten -> 256 weight dense layer -> 1 weight dense layer (logits) 를 순차적으로 통과시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \"\"\" define layers to use in call function\"\"\"\n",
    "        self.conv_1 = Conv2D(512, (3, 3), activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(256)\n",
    "        self.logits = Dense(1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\" let through x data into defined layers\n",
    "        Args:\n",
    "            x: image data to discriminate\n",
    "        Return:\n",
    "            logit: 1 digit logit to decide real or fake\"\"\"\n",
    "        x = self.conv_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "    \n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss 를 계산하기 위한, cross_entropy 함수를 정의하시오.\n",
    "### loss 를 계산하기 위한, optimizer 를 정의하시오.\n",
    "\n",
    "##### 현재 구분해야할 클래스가 가짜, 진실 총 두가지 클래스 이므로, binary crossentropy 함수를 사용한다.\n",
    "##### optimizer 는 가장 보편적인 adam optimizer 를 사용한다.\n",
    "##### discriminator 와 generator 둘다 모두 따로 학습이 되므로 각각 사용할 optimizer를 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가짜 이미지를 생성하기 위한, generator 를 정의해봅시다. \n",
    "#### generator 는 이미지를 생성하기 위해, NOISE 를 인풋으로 받고, 78 * 78 사이즈의 generated img 를 반환합니다.\n",
    "##### init 함수에는 generator가 사용할 layer들을 정의하고, call 함수에서 정의된 layer들에 input 데이터를 통과시키세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \"\"\" define layers to use in call function\"\"\"\n",
    "        self.dense_1 = Dense(7 * 7 * 1024)\n",
    "        self.reshape = Reshape((7, 7, 1024))\n",
    "        self.conv_1 = Conv2DTranspose(512, (3, 3), strides=(1, 1), padding='same')\n",
    "        self.conv_2 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')\n",
    "        self.conv_3 = Conv2DTranspose(1, (3, 3), strides=(2,2), padding='same', activation='tanh')\n",
    "        \n",
    "    def call(self, latent):\n",
    "        \"\"\" let through x data into defined layers\n",
    "        Args:\n",
    "            latent: noise\n",
    "        Return:\n",
    "            generated_img: 28 * 28 generated_imgs\"\"\"\n",
    "        x = self.dense_1(latent)\n",
    "        x = self.reshape(x)\n",
    "        assert x.shape == (BATCH_SIZE, 7, 7, 1024)\n",
    "        x = self.conv_1(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        assert x.shape == (BATCH_SIZE, 7, 7, 512)\n",
    "        x = self.conv_2(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        assert x.shape == (BATCH_SIZE, 14, 14, 256)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = self.conv_3(x)\n",
    "        assert x.shape == (BATCH_SIZE, 28, 28, 1)\n",
    "        return x\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator 가 제대로 작동하는지 확인해 봅시다. \n",
    "#### input 으로 100 차원의 noise 벡터를 batch_size개수 만큼 생성하고 generator를 통과해 나온 img를 그려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7, 7, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb4c9e3c88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGN5JREFUeJzt3XmQlNW5BvDnZRmBYZF1WHUAgUBQUQYkgYhGQ4DCIEkFsRIDpRE3kmvU8iYaczVVt8q6FVETjAm5oSIWEo3BxFgoImoMkRBmCIuyiA77vsgOIsN7/5gmd0TOc4aZobut8/yqKIZ+5u3+pul3ejnfOcfcHSKSnnq5PgARyQ01v0ii1PwiiVLziyRKzS+SKDW/SKLU/CKJUvOLJErNL5KoBtm8scaNG3uLFi1qXF+vXvh3FcsA4PDhwzRv3LgxzRs1alTj6z569CjNY8fepEkTmh8/fjyYNWjA/4tjt33o0CGan3POOTRnZ5BWVFTQ2oYNG9L82LFjNC8sLAxmBw4coLWxnyv2fxqrZ/f7xx9/TGuZ/fv348iRI1ad761V85vZcACPA6gP4H/d/WH2/S1atMB3vvMddn309lgTxO7spUuX0rxPnz4079WrVzBbsmQJrV21ahXNY83dv39/mu/evTuYtWrVitY2bdqU5gsWLKB5165dac5+Me3du5fWdujQgeYbN26k+aBBg4LZvHnzaO0FF1xA85UrV9K8R48eNGe/mLZs2UJr2S+OGTNm0NpPXE+1v/MUZlYfwBMARgDoA+B6M+MdJCJ5ozbv+QcCeN/dy939GIDfAxhdN4clImdbbZq/E4Cqr7s2ZS77BDObaGalZlZ65MiRWtyciNSls/5pv7tPdfcSdy+JfagmItlTm+bfDKBLlX93zlwmIp8BtWn+RQB6mFlXMysAMA7Ai3VzWCJytlltVvIxs5EAHkPlUN80d/9v9v3FxcX+wAMPBPNNmzbR29u+fXswKyoqorXNmjWj+YoVK2jOhqU6duxIa2PnNsTGu2NDiWwY8oMPPqC1w4YNo3lsOI4N5QF8KDF2v23ezF9IxoZ39+/fH8zatGlDa7du3Vqr2y4vL6c5ewscezywfNasWdi5c+fZH+d399kAZtfmOkQkN3R6r0ii1PwiiVLziyRKzS+SKDW/SKLU/CKJyup8/oqKCjr2Ghs7ZVNj27VrR2t37txJ81tvvZXmv/71r4NZbP51bMruF77wBZoXFxfTfNu2bcFs4MCBtPbEiRM0b9u2Lc1jY/FdunQJZuy8DQD48MMPaR6734cOHRrMysrKaC2bcgvE13/o2bMnzdl5BmztCID/3K+++iqtrUrP/CKJUvOLJErNL5IoNb9IotT8IolS84skKqtDfcePH6dDbs2bN6f1bOgmJjZkFVv1tHfv3sHs4MGDtDY2dBNbrTW20uwll1wSzOrXr09rY1O6165dS/PY0t9r1qyp8W3HtGzZkubPPPNMMOvcuTOtjS0bHhsKjC0Nvn79+hrfNuuT2HTgqvTML5IoNb9IotT8IolS84skSs0vkig1v0ii1PwiicrqOD/Ax4XZdF+ALyPNxuGB+Fh8bNos2432lVdeobWxHVtj2rdvT3O2jXZs6e6LLrqI5rFdfGPTatk07dhU5nfeeYfmsfNCNmzYEMz+/ve/09oJEybQPLbMfGxrc7atO5uiDfBt12OP86r0zC+SKDW/SKLU/CKJUvOLJErNL5IoNb9IotT8Iomq1Ti/ma0DcABABYDj7l7Cvt/d8dFHHwXz2BLXbJnp2Ljrvn37aB5bipktI3306FFaGxt7ZctbA/HltQsKCoLZueeeS2vfe+89ml944YU0j41Js/tmypQptLZv3740Z+P4AB8Pj21NPnnyZJpffPHFNI8tac5+9oceeojWsvNGYsvfV1UXJ/lc6e676uB6RCSL9LJfJFG1bX4H8KqZlZnZxLo4IBHJjtq+7B/i7pvNrB2AuWa2yt3fqvoNmV8KEwGgWbNmtbw5EakrtXrmd/fNmb93AHgBwKc2hnP3qe5e4u4lsQ/0RCR7atz8ZlZoZs1Ofg1gGAA+DUtE8kZtXvYXAXjBzE5ezzPuzue2ikjeqHHzu3s5AD7YeYqmTZtiyJAhwXz58uW0ns33b9GiBa2NveWIjdV//etfD2axrab/9re/0Tw2nj1z5kyaP/LII8EsthbAl770JZrffvvtNJ82bRrNx40bF8zYYwEAOnbsSPPY/c7WGog9XmL7HbBzCABg5MiRNGdbvvfp04fWDhgwIJg999xztLYqDfWJJErNL5IoNb9IotT8IolS84skSs0vkiir7TbJZ6J9+/Z+ww03BPNu3brRerbccWzaa3l5Oc0HDx5Mc7bkeGzIKba099VXX03z2HTl888/P5jNnTuX1saG+nr16kXz2Bbe7L7JnCMSxLb3BoB+/frRnC31HttiO7ale2wocNmyZTRnU61jy6EXFRUFsylTpmDTpk38js3QM79IotT8IolS84skSs0vkig1v0ii1PwiiVLziyQqq1t0FxYWYuDATy3282+lpaW0ni0jHdvOec+ePTR/7LHHaD58+PBgtnDhQlob2/6bLb0NxKflzp8/P5jFpio3bNiQ5rH/k0svvZTm69evD2Z33XUXrY1NJ27dujXNV69eHczGjBlDa++55x6aDx06lOaxrc3ZWH1snJ89HmL/n1XpmV8kUWp+kUSp+UUSpeYXSZSaXyRRan6RRKn5RRKV1XH+I0eO0OW5Y2OUbFvjUaNG0dp27drRPDaWzsbyY2PGd9xxB81/9KMf0XzdunU0v+CCC4LZsWPHaG3sHAS2NTkArFixguYVFRXB7P7776e1tVljAeBj7Vu2bKG1d955J8137txJ89hS8ezYfvGLX9Da6667LpjF/r+r0jO/SKLU/CKJUvOLJErNL5IoNb9IotT8IolS84skKjrOb2bTAIwCsMPd+2YuawXgWQDFANYBGOvufEAYlWO+bC312Jz7W265JZjFxjfffvttmk+ePJnmhw4dCmZHjhyhtQsWLKD566+/TvPbbruN5vPmzQtm5513Hq1leyEA8ftlzpw5NC8rKwtm27Zto7Wx/Qp27dpFczafPzZOz9bVB+L3a23m88f2cajN/hVVVeeZ/3cATl3J4ocA5rl7DwDzMv8Wkc+QaPO7+1sATn1KHg3gqczXTwG4to6PS0TOspq+5y9y962Zr7cBCL+GEZG8VOsP/Lxys7/ghn9mNtHMSs2sNPbeWESyp6bNv93MOgBA5u8doW9096nuXuLuJY0bN67hzYlIXatp878IYHzm6/EA/lw3hyMi2RJtfjObCWABgF5mtsnMbgLwMICvmNkaAFdn/i0inyHRcX53vz4QXVWTG2RzsNm8dABYtGhRMOvcuTOt7dGjB80ff/xxmpeXlwez2BrurVq1onnz5s1pHtuTgI3trlq1itZ27NiR5jfeeCPNlyxZQnO27v+AAQNobWws/hvf+AbN2Vh77PHwpz/9ieYtW7ak+datW2nerFmzYFb5MdrZpzP8RBKl5hdJlJpfJFFqfpFEqflFEqXmF0lUVpfudne6lHNseikbJowNrcSWBb/mmmtoHptuzMSmf7Zo0YLmc+fOpbmZBbPY8taxabGxocAPPviA5p06dQpmixcvprWxIa/YlF+2rHjs54oNM3bo0IHmsaHnv/71r8Fs0KBBtJZNoz6TU+j1zC+SKDW/SKLU/CKJUvOLJErNL5IoNb9IotT8IonK6jh/QUEBHV+NbQf9j3/8I5hNmDCB1rLlrQFg+vTpNO/du3cw69OnD62dOnUqzWPbi8fGw8ePHx/Mbr31Vlo7adIkmsemOrNt0wHgiSeeCGY33XQTrY2d3xAbi7/sssuCWew+jU2F/v73v0/z2OOJLc/9z3/+k9ZedVV4Nv2//vUvWluVnvlFEqXmF0mUml8kUWp+kUSp+UUSpeYXSZSaXyRRWR3nNzMUFBQEc5YBfIvu2Nzvu+66i+ZHjx6l+ezZs4MZW1IciM/tvvfee2l+7bV8H9Q1a9YEs8svv5zW7tgR3GwJALBhwwaa//SnP6U5OwchNia9e/dumnfp0oXmJSUlwaywsJDWjhgxguY9e/ak+Xe/+12as3UUjh8/TmtZn7C1HU6lZ36RRKn5RRKl5hdJlJpfJFFqfpFEqflFEqXmF0lUdJzfzKYBGAVgh7v3zVz2IICbAZycUH2fu4cHwjMOHz6MsrKyYB7byvrAgQPBLHaOQGwr6S9+8Ys0Z9tgFxcX01q2TTUA3H333TRv3bo1zdmxfe5zn6O1sf0Onn/+eZo3aMAfQmwsn22hDcT3M+jWrRvNFy5cGMzYYwkANm/eXOPrBoBt27bRnG1P3qRJE1rLzgM4k+29q/PM/zsAw09z+aPu3i/zJ9r4IpJfos3v7m8BqPl2NSKSl2rznn+SmS0zs2lm1rLOjkhEsqKmzf8kgO4A+gHYCuCR0Dea2UQzKzWz0tj58yKSPTVqfnff7u4V7n4CwG8ADCTfO9XdS9y9pFGjRjU9ThGpYzVqfjOrukXpGADv1M3hiEi2VGeobyaAKwC0MbNNAP4LwBVm1g+AA1gHIDzXVkTyUrT53f3601z825rcWEFBAR2bje1jz/aCP3bsGK3du3cvzWNj8S+99FIwi51jEBvzZXO7gfh4OBtrX758Oa295ppraP7mm2/SvH379jRn+9j//Oc/p7XXX3+6h97/i61FMG7cuBplAPDyyy/T/Omnn6Z59+7daT5nzpxgVq8ef0HOcs3nF5EoNb9IotT8IolS84skSs0vkig1v0iisrp0t7vTIbmNGzfS+v379wez2NDKvn37aN6rVy+as2WkY0tIx5aJXrFiBc0PHjxIc/azt2nTplbXvXTpUpoPGzaM5mxb9R/84Ae0dubMmTSPbS/+yiuvBLOhQ4fS2vPPP5/m3/ve92gee7xdeumlwWz9+vW0duXKlcHsyJEjtLYqPfOLJErNL5IoNb9IotT8IolS84skSs0vkig1v0iisjrO36hRI/To0SOYN2zYkNYfOnSIXjcTm7q6adMmmr///vvB7Oabb6a1sSm9MbHlsc8999xg1r9/f1p7zjnn0Lxdu3Y0Z+P4AP/ZKyoqaO3VV19N89gS15///OeD2be+9S1aG5tmHTu3Y8KECTSfPn16MBs0aBCtfffdd4OZpvSKSJSaXyRRan6RRKn5RRKl5hdJlJpfJFFqfpFE2Zls6Vtbbdu29dGjRwfzvn370no2Znz48GFaGxuXjZ1jsHr16mDWp08fWhvb7jm2BPWFF15IczYnn81pB+LnP3Tt2pXm8+fPpzlbgyE2Js1qAaBTp040Z3Pb2TbXQHzZ8PLycprHtj5nj5nt27fTWrZ1+UMPPYS1a9dWa7Bfz/wiiVLziyRKzS+SKDW/SKLU/CKJUvOLJErNL5Ko6Hx+M+sCYDqAIgAOYKq7P25mrQA8C6AYwDoAY939Q3ZdTZo0oeuVx8bqP/roo2DWuHFjWrtgwQKax8aM2dhrbKz8Jz/5Cc0HDBhA89g22Gw+/wMPPEBr2fkLADB58mSa//jHP6b5Cy+8EMx69uxJa2PnPxQVFdGc7YcQW6fg+eefp/lVV11F87Vr19J8w4YNwWzZsmW0lu05cCbn7VTnmf84gLvdvQ+AQQDuMLM+AH4IYJ679wAwL/NvEfmMiDa/u29198WZrw8AWAmgE4DRAJ7KfNtTAK49WwcpInXvjN7zm1kxgEsALARQ5O4nz2Hchsq3BSLyGVHt5jezpgD+COBOd//ESdde+UbjtG82zGyimZWaWWlsXzgRyZ5qNb+ZNURl489w91mZi7ebWYdM3gHAaT+dcfep7l7i7iVNmzati2MWkToQbX6rnHr1WwAr3b3qR78vAhif+Xo8gD/X/eGJyNlSnaW7BwO4AcByM1uSuew+AA8DeM7MbgKwHsDY2BUdPnyYbvn88ccf03q21DMb7gLiWzLPmTOH5myL7tmzZ9PaIUOG0PyrX/0qzdmwEMCX3/72t79Na3/5y1/SPLYkOtsuGgB27twZzEaNGkVrf/WrX9H89ttvpzkbvi0tLaW17LiB+BbeU6ZMoTnrgzfffJPWLl68OJjFhsurija/u88HEJofzAc7RSRv6Qw/kUSp+UUSpeYXSZSaXyRRan6RRKn5RRKV1S2669Wrh8LCwmD+4Yd0RjCdrli/fn1au2/fPprHptW+/vrrwSw2nXjsWH4KREFBAc1PnDhBc3bm5L333ktrY0t7f/Ob36R5586daX7jjTcGs3Xr1tHa2LTav/zlLzS/7LLLglnsPl24cCHNmzdvTvN77rmH5myKeOwcgpYtWwazWB9UpWd+kUSp+UUSpeYXSZSaXyRRan6RRKn5RRKl5hdJVNbH+dnc89gS1ew8gNi47Z49e2geG2tn6wHUq8d/h65fv57msWXDY3PLWf2zzz5La6+9lq+7umjRIprv3buX5jNmzAhmvXv3prWxbbTZMvAAX1b8tttuo7Wx/7PYeSO7du2i+dtvvx3MYuP8rVu3Dmasv06lZ36RRKn5RRKl5hdJlJpfJFFqfpFEqflFEqXmF0lUVsf53Z2uvR/b0YeNrW7bto3WsrndALBq1Sqas7HVtm3b0to//OEPNB80aBDN+/XrR3M27z02lr5lyxaad+vWjebDhw+nOVtHPnbdsfn+sTXq2c/esWNHWnvFFVfQnM3HB4Arr7yS5rNmzQpmsb0SunfvHsxie19UpWd+kUSp+UUSpeYXSZSaXyRRan6RRKn5RRKl5hdJVHSc38y6AJgOoAiAA5jq7o+b2YMAbgZwcrL5fe5ON6o3MzRoEL7JZs2a0WN54403gtnFF19Ma2N7nrdr147mL7/8cjCL7TN/3nnn0XzmzJk0f+2112g+ZsyYYHbw4EFa26pVK5ovX76c5ps3b6Y5W09g4sSJtDY2zt+kSROaz5kzJ5iNHDmS1j755JM0//KXv0zzefPm0fxrX/taMGOPcwB074vY2hJVVeckn+MA7nb3xWbWDECZmc3NZI+6+8+qfWsikjeize/uWwFszXx9wMxWAuBLz4hI3juj9/xmVgzgEgAn9zKaZGbLzGyamZ12DyEzm2hmpWZWGjsdU0Syp9rNb2ZNAfwRwJ3uvh/AkwC6A+iHylcGj5yuzt2nunuJu5fE3qOJSPZUq/nNrCEqG3+Gu88CAHff7u4V7n4CwG8ADDx7hykidS3a/GZmAH4LYKW7T65yeYcq3zYGwDt1f3gicrZU59P+wQBuALDczJZkLrsPwPVm1g+Vw3/rANwSu6KKigocOHAgmBcVFdH6iy66KJgVFxfT2iFDhtCcbcENAJMmTQpmseWSy8rKaB6bXvroo4/S/KWXXgpma9eupbW9evWieWyYcsWKFTS/7rrrglnDhg1p7f79+2keW+J6xIgRweytt96itT/7GR/E2rhxI813795N89WrVwezwYMH1+q6q6s6n/bPB2CnieiYvojkN53hJ5IoNb9IotT8IolS84skSs0vkig1v0iisrp0d4MGDdCmTZtgHlt+m00/Zdt3A8DKlStp3rVrV5qzrapj5yewnxkAxo4dS/OpU6fSvEOHDsEsNsUzNt4dW16bTS8FgLlz5waz/v3709rYOP57771Hc3b+RGwK99KlS2lev359msemOsemoDM7duwIZrFtzavSM79IotT8IolS84skSs0vkig1v0ii1PwiiVLziyTK3D17N2a2E8D6Khe1AbArawdwZvL12PL1uAAdW03V5bGd7+58z/iMrDb/p27crNTdS3J2AES+Hlu+HhegY6upXB2bXvaLJErNL5KoXDc/P2k9t/L12PL1uAAdW03l5Nhy+p5fRHIn18/8IpIjOWl+MxtuZqvN7H0z+2EujiHEzNaZ2XIzW2JmpTk+lmlmtsPM3qlyWSszm2tmazJ/n3abtBwd24Nmtjlz3y0xM74V7tk7ti5m9oaZrTCzd83sPzKX5/S+I8eVk/st6y/7zaw+gPcAfAXAJgCLAFzv7nwB+Cwxs3UAStw952PCZnY5gIMAprt738xl/wNgj7s/nPnF2dLd/zNPju1BAAdzvXNzZkOZDlV3lgZwLYAJyOF9R45rLHJwv+XimX8ggPfdvdzdjwH4PYDROTiOvOfubwHYc8rFowE8lfn6KVQ+eLIucGx5wd23uvvizNcHAJzcWTqn9x05rpzIRfN3AlB1u5NNyK8tvx3Aq2ZWZmYTc30wp1GU2TYdALYB4MsIZV905+ZsOmVn6by572qy43Vd0wd+nzbE3S8FMALAHZmXt3nJK9+z5dNwTbV2bs6W0+ws/W+5vO9quuN1XctF828G0KXKvztnLssL7r458/cOAC8g/3Yf3n5yk9TM3+EF3bIsn3ZuPt3O0siD+y6fdrzORfMvAtDDzLqaWQGAcQBezMFxfIqZFWY+iIGZFQIYhvzbffhFAOMzX48H8OccHssn5MvOzaGdpZHj+y7vdrx296z/ATASlZ/4fwDg/lwcQ+C4ugFYmvnzbq6PDcBMVL4M/BiVn43cBKA1gHkA1gB4DUCrPDq2pwEsB7AMlY3WIUfHNgSVL+mXAViS+TMy1/cdOa6c3G86w08kUfrATyRRan6RRKn5RRKl5hdJlJpfJFFqfpFEqflFEqXmF0nU/wHr0mkMGfzc3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent = tf.random.normal([BATCH_SIZE, 100])\n",
    "generated_img = generator(latent)\n",
    "plt.imshow(generated_img[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞서 생성한 generated_img를 정의해둔 discriminator 에 통과시켜 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = discriminator(generated_img)\n",
    "assert decision.shape == (32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generator를 학습시키기 위한 generator loss 함수를 정의합니다.\n",
    "#### generator가 학습하기 위해서는 discriminator 가 진짜와 generated img를 구분하지 못해야 합니다.\n",
    "#### 즉 generated img 를 discriminator가 진짜라고 간주해야 합니다.\n",
    "#### 따라서 fake_output이 진짜 (1) 로 되도록 loss 를 정의합니다. \n",
    "##### hint 앞서서 정의한 cross_entropy를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    \"\"\"define generator loss function\n",
    "    Args:\n",
    "        fake_output: logit output from discriminator(discriminator's input is generated_img)\n",
    "    Returns:\n",
    "        loss: loss value for generator\"\"\"\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discriminator 를 학습시키기 위한 discriminator loss 함수를 정의합니다.\n",
    "#### discriminator 를 학습하기 위해서는 진짜 이미지와, generated img를 잘 구분해야 합니다.\n",
    "#### 따라서 real_output은 1로, fake_output은 0 으로 다가가도록 loss 를 정의합니다.\n",
    "##### hint 앞서서 정의한 cross_entropy를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"define discriminator loss function\n",
    "    Args:\n",
    "        real_output: logit output from discriminator(discriminator's input is real img)\n",
    "        fake_output: logit output from discriminator(discriminator's input is generated_img)\n",
    "    Returns:\n",
    "        total_loss: loss value for discriminator \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이제 전체적인 학습과정을 정의해 봅시다.\n",
    "#### generator를 통해 이미지를 생성하고, 정답 이미지와, 생성된 이미지 각각 discriminator에 통과시킨 뒤, 각각의 output을 discriminator_loss 함수에 넣어 discriminator loss 를 구합니다.\n",
    "#### generator를 통해 생성된 이미지를 generator_loss 함수에 넣어 generator loss 를 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_imgs = generator(noise, training=True)\n",
    "        fake_outputs = discriminator(generated_imgs, training=True)\n",
    "        real_outputs = discriminator(images)\n",
    "        gen_loss = generator_loss(generated_imgs)\n",
    "        disc_loss = discriminator_loss(real_outputs, fake_outputs)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    print(f\"g_loss == {gen_loss:4.2f} / d_loss == {disc_loss:4.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습된 generator를 사용하여 생성해 낸 이미지를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(epoch, test_input):\n",
    "    generated_img = generator(test_input, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(generated_img.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(denormalized(generated_img[i, :, :, 0]), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f\"saved_img-epoch{epoch}.png\")\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7, 7, 1024)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6a71dae95afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch == {epoch}... printing inference img...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mgenerate_and_save_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-17268eac440c>\u001b[0m in \u001b[0;36mgenerate_and_save_images\u001b[0;34m(epoch, test_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_and_save_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgenerated_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-4d4dae999a67>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, latent)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = tf.random.normal([4 * 4, 100])\n",
    "for epoch in range(5):\n",
    "    for train_imgs in train_dataset:\n",
    "        train_step(train_imgs)\n",
    "        print(f\"epoch == {epoch}... printing inference img...\")\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(epoch, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
